# ═══════════════════════════════════════════════════════════════════════════════
# TELEGRAM AI SAAS - Docker Compose with Monitoring
# ═══════════════════════════════════════════════════════════════════════════════

version: '3.9'

services:
  # ═══════════════════════════════════════════════════════════════════════
  # REVERSE PROXY - Caddy 2
  # ═══════════════════════════════════════════════════════════════════════
  caddy:
    image: caddy:2-alpine
    container_name: telegram-ai-caddy
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./Caddyfile:/etc/caddy/Caddyfile:ro
      - caddy_data:/data
      - caddy_config:/config
    networks:
      - frontend
    depends_on:
      - api

  # ═══════════════════════════════════════════════════════════════════════
  # API PRINCIPALE
  # ═══════════════════════════════════════════════════════════════════════
  api:
    build:
      context: ./api
      dockerfile: Dockerfile
    container_name: telegram-ai-api
    restart: unless-stopped
    environment:
      - NODE_ENV=production
      - DATABASE_URL=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}
      - REDIS_URL=redis://redis:6379
      - TELEGRAM_BOT_TOKEN=${TELEGRAM_BOT_TOKEN}
      - TELEGRAM_WEBHOOK_SECRET=${TELEGRAM_WEBHOOK_SECRET}
      - LEMON_API_KEY=${LEMON_API_KEY}
      - LEMON_WEBHOOK_SECRET=${LEMON_WEBHOOK_SECRET}
      - LEMON_STORE_ID=${LEMON_STORE_ID}
      - ENCRYPTION_KEY=${ENCRYPTION_KEY}
      - SESSION_SECRET=${SESSION_SECRET}
      - JWT_SECRET=${JWT_SECRET}
      - LOG_LEVEL=${LOG_LEVEL:-info}
      # Monitoring
      - SENTRY_DSN=${SENTRY_DSN:-}
    networks:
      - frontend
      - backend
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:3000/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # ═══════════════════════════════════════════════════════════════════════
  # WORKER - BullMQ
  # ═══════════════════════════════════════════════════════════════════════
  worker:
    build:
      context: ./worker
      dockerfile: Dockerfile
    container_name: telegram-ai-worker
    restart: unless-stopped
    environment:
      - NODE_ENV=production
      - DATABASE_URL=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}
      - REDIS_URL=redis://redis:6379
    networks:
      - backend
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy

  # ═══════════════════════════════════════════════════════════════════════
  # REDIS - Cache & Queue
  # ═══════════════════════════════════════════════════════════════════════
  redis:
    image: redis:7-alpine
    container_name: telegram-ai-redis
    restart: unless-stopped
    command: |
      redis-server
      --appendonly yes
      --maxmemory 256mb
      --maxmemory-policy allkeys-lru
    volumes:
      - redis_data:/data
    networks:
      - backend
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 3

  # ═══════════════════════════════════════════════════════════════════════
  # POSTGRESQL
  # ═══════════════════════════════════════════════════════════════════════
  postgres:
    image: postgres:15-alpine
    container_name: telegram-ai-postgres
    restart: unless-stopped
    environment:
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_DB=${POSTGRES_DB}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    networks:
      - backend
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}"]
      interval: 10s
      timeout: 5s
      retries: 3

  # ═══════════════════════════════════════════════════════════════════════
  # PROMETHEUS - Metrics Collection
  # ═══════════════════════════════════════════════════════════════════════
  prometheus:
    image: prom/prometheus:latest
    container_name: telegram-ai-prometheus
    restart: unless-stopped
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.enable-lifecycle'
    networks:
      - monitoring
    depends_on:
      - api

  # ═══════════════════════════════════════════════════════════════════════
  # GRAFANA - Dashboards
  # ═══════════════════════════════════════════════════════════════════════
  grafana:
    image: grafana/grafana:latest
    container_name: telegram-ai-grafana
    restart: unless-stopped
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=${GRAFANA_ADMIN_USER:-admin}
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_ADMIN_PASSWORD:-admin}
      - GF_USERS_ALLOW_SIGN_UP=false
    volumes:
      - ./monitoring/grafana/provisioning:/etc/grafana/provisioning:ro
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana/dashboards:/var/lib/grafana/dashboards:ro
    networks:
      - monitoring
    depends_on:
      - prometheus

  # ═══════════════════════════════════════════════════════════════════════
  # GRAFANA ALERTMANAGER
  # ═══════════════════════════════════════════════════════════════════════
  alertmanager:
    image: prom/alertmanager:latest
    container_name: telegram-ai-alertmanager
    restart: unless-stopped
    ports:
      - "9093:9093"
    volumes:
      - ./monitoring/alertmanager.yml:/etc/alertmanager/alertmanager.yml:ro
      - alertmanager_data:/alertmanager
    command:
      - '--config.file=/etc/alertmanager/alertmanager.yml'
      - '--storage.path=/alertmanager'
    networks:
      - monitoring

  # ═══════════════════════════════════════════════════════════════════════
  # SENTRY - Error Tracking (Optional - requires external Sentry instance)
  # ═══════════════════════════════════════════════════════════════════════
  # Uncomment and configure if self-hosting Sentry
  # sentry-web:
  #   image: sentry:latest
  #   container_name: telegram-ai-sentry
  #   restart: unless-stopped
  #   ports:
  #     - "9000:9000"
  #   environment:
  #     - SENTRY_SECRET_KEY=${SENTRY_SECRET_KEY}
  #     - SENTRY_POSTGRES_HOST=postgres
  #     - SENTRY_REDIS_HOST=redis
  #   depends_on:
  #     - postgres
  #     - redis

# ═══════════════════════════════════════════════════════════════════════
# VOLUMES
# ═══════════════════════════════════════════════════════════════════════
volumes:
  caddy_data:
  caddy_config:
  redis_data:
  postgres_data:
  prometheus_data:
  grafana_data:
  alertmanager_data:

# ═══════════════════════════════════════════════════════════════════════
# NETWORKS
# ═══════════════════════════════════════════════════════════════════════
networks:
  frontend:
    driver: bridge
  backend:
    driver: bridge
  monitoring:
    driver: bridge
